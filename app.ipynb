{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Local Imports\n",
    "from src.seg2map import map_interface\n",
    "from src.seg2map import log_maker #must be the first module loaded to create logs folder\n",
    "\n",
    "# External Imports\n",
    "import ee\n",
    "from google.auth import exceptions as google_auth_exceptions\n",
    "\n",
    "# suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate and Initialize with Google Earth Engine (GEE)\n",
    "\n",
    "- Run this cell to initialize with GEE which will allow you to download remote sensing data from GEE.\n",
    "\n",
    "### First Time Users\n",
    "\n",
    "- In order to use Google Earth Engine (GEE) you will need to sign up to request access to use Google Earth Engine.https://signup.earthengine.google.com. You will only need to do this once and it takes only a day to get your account verified.\n",
    "\n",
    "### How `ee.Authenticate()` works\n",
    "\n",
    "- In order to initialize with GEE you will need an authorization token with is obtained by running `ee.Authenticate()`.This token lasts 7 days and during those 7 days you will not need to authenticate with google earth engine with an access code. Once the 7 days are up you will need to reauthenticate to use GEE again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except google_auth_exceptions.RefreshError as exception:\n",
    "    print(\"Please authenticate with Google:\\n\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use The Map\n",
    "\n",
    "---\n",
    "1.  Click `Save Settings` Button\n",
    "2. Use the rectangle tool to draw a ROI along the coastline.\n",
    "3. Load transects into your bounding box with the `Load Transects` button. If any exist for the bounding box you selected they should appear.\n",
    "4. Click the ROIs you want to download.\n",
    "5. Once you've selected all the ROIs you want to download click `Downlod Imagery`\n",
    " - If any of the ROIs succesfully download they will have their own folder with all their data in the `data` directory in the `seg2map` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from coastseg.map_UI import UI\n",
    "from src.seg2map.map_UI import UI\n",
    "from src.seg2map.map_interface import CoastSeg_Map\n",
    "\n",
    "coastsegmap=CoastSeg_Map()\n",
    "coastseg_ui = UI(coastsegmap)\n",
    "coastseg_ui.create_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.load_feature_on_map(\"rois\", gdf=roi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.load_feature_on_map(\"rois\",file =\"multiple_rois2.geojson\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_roi_ids = [1,2,3]\n",
    "set(new_roi_ids)\n",
    "ids=[1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath =r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\multiple_rois2.geojson'\n",
    "roi_gdf=gpd.read_file(filepath)\n",
    "roi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = [\"12\",\"22\",\"33\"]\n",
    "roi_gdf['id'] = new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf.to_file(filename = \"multiple_rois2.geojson\",drive=\"driver='GeoJSON'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ids = [\"1\",\"2\",\"3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ids = [\"1\",\"2\",\"3\"]\n",
    "new_ids= []\n",
    "for i in range(len(roi_gdf)):\n",
    "    new_id =create_roi_id(current_ids)\n",
    "    current_ids.extend(new_id)\n",
    "    new_ids.extend(new_id)\n",
    "roi_gdf['id'] = new_ids\n",
    "return roi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ids = [\"1\",\"2\",\"3\"]\n",
    "new_ids= []\n",
    "for i in range(len(roi_gdf)):\n",
    "    new_id =create_roi_id(current_ids)\n",
    "    current_ids.extend(new_id)\n",
    "    new_ids.extend(new_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf['id'] = new_ids\n",
    "roi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = [create_roi_id(current_ids) for idx in range((len(roi_gdf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roi_id(current_ids: list[str], new_id: str = None) -> str:\n",
    "    \"\"\"create a new id that does not exist in the current_ids. If the new_id provided does\n",
    "    exist within the array return None\n",
    "    Args:\n",
    "        current_ids (list[str]): list of ids\n",
    "        new_id (str, optional): id If not provided one will be created. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: id that is not in current_ids or None if it exists within current_ids\n",
    "    \"\"\"\n",
    "    if new_id is None:\n",
    "        new_id = \"1\" if current_ids == [] else str(int(max(current_ids)) + 1)\n",
    "\n",
    "    if new_id not in current_ids:\n",
    "        return new_id\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gpd.read_file(\"map.geojson\")\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line=gpd.read_file(\"line.geojson\")\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(line.loc[0]['geometry'],shapely.LineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = getattr(line.loc[0]['geometry'],'coords',None)\n",
    "callable(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(hasattr(gdf.loc[0]['geometry'],'coords'))\n",
    "except Exception as e:\n",
    "    print(hasattr(gdf.loc[0]['geometry'],'exterior'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"coords\" in dir(gdf.loc[0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.loc[0]['geometry'].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.loc[0]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS(gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_CRS = CRS('epsg:4326')\n",
    "map_CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf= gdf.to_crs('EPSG:3587')\n",
    "new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(new_gdf.crs) != 'epsg:4326':\n",
    "    new_gdf = new_gdf.to_crs(map_CRS)\n",
    "new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_gdf.loc[0]['geometry'].exterior.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gdf.loc[0]['geometry'].exterior.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".exterior.coords.xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely.geometry.polygon.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(new_gdf.loc[0]['geometry'],shapely.geometry.polygon.Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(new_gdf.loc[0]['geometry'],shapely.Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.loc[0]['geometry'].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.loc[0]['geometry'] == gdf.loc[0]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(gdf.crs) != 'epsg:4326':\n",
    "    gdf = gdf.to_crs('epsg:4326')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(new_gdf.crs) != 'epsg:4326':\n",
    "    new_gdf = new_gdf.to_crs(map_CRS)\n",
    "new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_ids=set(new_roi_ids)&set(ids)\n",
    "repeat_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(coastsegmap.rois.gdf['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_roi_ids_to_map(pass in list of ids to add)\n",
    "# raises error if any of them already exist on map\n",
    "\n",
    "# load_feature\n",
    "# calls add_roi_ids_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config_path = r\"C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename25\\ID_1_dates_2010-01-01_to_2010-12-31\\config.json\"\n",
    "def write_to_json(filepath: str, settings: dict):\n",
    "    \"\"\" \"Write the  settings dictionary to json file\"\"\"\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        json.dump(settings, output_file)\n",
    "write_to_json(config_path,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_path = r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename8\\ID_1_dates_2020-01-01_to_2020-12-15\\merged_multispectral.tif'\n",
    "tif_path =r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename16\\ID_1_dates_2010-01-02_to_2013-12-31\\multiband'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s =set([1,23,4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(s):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "class DownloadBands(enum.Enum):\n",
    "    MULTIBAND = \"multiband\"\n",
    "    SINGLEBAND = \"singleband\"\n",
    "    BOTH = \"both\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownloadBands.MULTIBAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownloadBands.MULTIBAND.name == \"multiband\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat']\n",
    "\n",
    "# tuple\n",
    "mammals = ['tiger', 'elephant','dog']\n",
    "\n",
    "animals.extend(mammals)\n",
    "\n",
    "print('Updated list:', set(animals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.map.add_raster(tif_path, layer_name='DEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coastsegmap.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def delete_empty_dirs(dir_path: str):\n",
    "    \"\"\"\n",
    "    Recursively delete all empty directories within a directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_path : str\n",
    "        The path to the directory where the search for empty directories begins.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for subdir in os.scandir(dir_path):\n",
    "        if subdir.is_dir():\n",
    "            subdir_path = subdir.path\n",
    "            if not os.listdir(subdir_path):\n",
    "                os.removedirs(subdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_empty_dirs(tif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "multipath = r\"C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename13\"\n",
    "\n",
    "for i in os.scandir(multipath ):\n",
    "    print(i.path)\n",
    "    print(i.name)\n",
    "    print(os.path.isdir(i.path))\n",
    "    print(os.listdir(i.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(subdir:str,dir_list:set):\n",
    "    if not os.path.isdir(subdir.path):\n",
    "        return dir_list\n",
    "    if os.path.isdir(subdir.path):\n",
    "        dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_path = r\"C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename17\\ID_1_dates_2010-01-01_to_2015-12-30\"\n",
    "import os\n",
    "# for i in os.scandir(multipath):\n",
    "#     if os.path.isdir(i.path):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "def find_subdirectories(directory: str) -> List[str]:\n",
    "    subdirectories = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for d in dirs:\n",
    "            subdirectories.append(os.path.join(root, d))\n",
    "    return subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_subdirectories(roi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zip(path):\n",
    "    # Get a list of all the zipped files in the directory\n",
    "    zipped_files = [\n",
    "        os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".zip\")\n",
    "    ]\n",
    "    # Remove each zip file\n",
    "    for zipped_file in zipped_files:\n",
    "        os.remove(zipped_file)\n",
    "\n",
    "\n",
    "def unzip(path):\n",
    "    # Get a list of all the zipped files in the directory\n",
    "    zipped_files = [\n",
    "        os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".zip\")\n",
    "    ]\n",
    "    # Unzip each file\n",
    "    for zipped_file in zipped_files:\n",
    "        with zipfile.ZipFile(zipped_file, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(path)\n",
    "\n",
    "\n",
    "def unzip_files(paths):\n",
    "    # Create a thread pool with a fixed number of threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit a unzip task for each directory\n",
    "        futures = [executor.submit(unzip, path) for path in paths]\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "\n",
    "def remove_zip_files(paths):\n",
    "    # Create a thread pool with a fixed number of threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit a remove_zip task for each directory\n",
    "        futures = [executor.submit(remove_zip, path) for path in paths]\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "\n",
    "def unzip_data(parent_dir: str):\n",
    "    subdirs = find_subdirectories(parent_dir)\n",
    "    unzip_files(subdirs)\n",
    "    remove_zip_files(subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os, json, shutil\n",
    "from glob import glob\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "import platform\n",
    "import tqdm\n",
    "import tqdm.auto\n",
    "import zipfile\n",
    "from area import area\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# unzip_data(roi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork'\n",
    "filepath = filepath or os.path.abspath(os.getcwd())\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirs(parent_dir:str):\n",
    "    # Get a list of all the subdirectories in the parent directory\n",
    "    subdirectories = []\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        for d in dirs:\n",
    "            subdirectories.append(os.path.join(root, d))\n",
    "    return subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\data\\sitename18'\n",
    "subdirs = get_subdirs(dir_path)\n",
    "remove_dirs = [subdir for subdir in subdirs if len(os.listdir(subdir)) == 0]\n",
    "print(remove_dirs)\n",
    "for remove_dir in remove_dirs:\n",
    "    os.removedirs(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "44f62ae1464d1bd94d46095295cce32bb1c15ab9a6effc0c50f8e5f2c4f28382"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
