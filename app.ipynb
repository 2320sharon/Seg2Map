{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Local Imports\n",
    "from src.seg2map import map_interface\n",
    "from src.seg2map import log_maker #must be the first module loaded to create logs folder\n",
    "\n",
    "# External Imports\n",
    "import ee\n",
    "from google.auth import exceptions as google_auth_exceptions\n",
    "\n",
    "# suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate and Initialize with Google Earth Engine (GEE)\n",
    "\n",
    "- Run this cell to initialize with GEE which will allow you to download remote sensing data from GEE.\n",
    "\n",
    "### First Time Users\n",
    "\n",
    "- In order to use Google Earth Engine (GEE) you will need to sign up to request access to use Google Earth Engine.https://signup.earthengine.google.com. You will only need to do this once and it takes only a day to get your account verified.\n",
    "\n",
    "### How `ee.Authenticate()` works\n",
    "\n",
    "- In order to initialize with GEE you will need an authorization token with is obtained by running `ee.Authenticate()`.This token lasts 7 days and during those 7 days you will not need to authenticate with google earth engine with an access code. Once the 7 days are up you will need to reauthenticate to use GEE again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except google_auth_exceptions.RefreshError as exception:\n",
    "    print(\"Please authenticate with Google:\\n\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use The Map\n",
    "\n",
    "---\n",
    "1.  Click `Save Settings` Button\n",
    "1. Use the rectangle tool to draw a bounding box along the coastline.\n",
    "2. Click `Generate ROI` to create ROI rectangles along the coastline in the bounding box. This may take some time.\n",
    "- You should see a coastline appear in yellow and some rectangles along it.\n",
    "3. Load transects into your bounding box with the `Load Transects` button. If any exist for the bounding box you selected they should appear.\n",
    "4. Click the ROIs you want to download.\n",
    "5. Once you've selected all the ROIs you want to download click `Downlod Imagery`\n",
    " - If any of the ROIs succesfully download they will have their own folder with all their data in the `data` directory in the `CoastSeg` directory\n",
    "6. To extract a timeseries of shorelines for the ROIs you downloaded click `Extract Shorelines`\n",
    "7. If any shorelines were extracted you can compute the cross distances along the transects and shoreline by clicking `Compute Transects` and save the output to a json file in the roi directory\n",
    "8. If any shorelines were extracted you can compute the cross distances along the transects and shoreline by clicking `Save Transects CSV`  and save the output to a csv in the roi directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from coastseg.map_UI import UI\n",
    "from src.seg2map.map_UI import UI\n",
    "from src.seg2map.map_interface import CoastSeg_Map\n",
    "\n",
    "coastsegmap=CoastSeg_Map()\n",
    "coastseg_ui = UI(coastsegmap)\n",
    "coastseg_ui.create_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"1\"][\"geometry\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"1\"].bounds.drop(index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"].boundary.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coastsegmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9404/1268620385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# polygon = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"][\"geometry\"].iloc[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpolygon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoastsegmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrois\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoastsegmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrois\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mmyPolygons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coastsegmap' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString, MultiPolygon, Polygon\n",
    "from shapely.ops import split\n",
    "def splitPolygon(polygon, nx, ny):\n",
    "    minx, miny, maxx, maxy = polygon.bounds.iloc[0]\n",
    "    dx = (maxx - minx) / nx  # width of a small part\n",
    "    dy = (maxy - miny) / ny  # height of a small part\n",
    "    horizontal_splitters = [LineString([(minx, miny + i*dy), (maxx, miny + i*dy)]) for i in range(ny)]\n",
    "    vertical_splitters = [LineString([(minx + i*dx, miny), (minx + i*dx, maxy)]) for i in range(nx)]\n",
    "    splitters = horizontal_splitters + vertical_splitters\n",
    "    result = polygon[\"geometry\"].iloc[0]\n",
    "    for splitter in splitters:\n",
    "        result = MultiPolygon(split(result, splitter))\n",
    "    return result\n",
    "\n",
    "# polygon = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"][\"geometry\"].iloc[0]\n",
    "polygon = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"]\n",
    "myPolygons = splitPolygon(polygon, 5, 5)\n",
    "import geopandas as gpd\n",
    "gdfR   = gpd.GeoDataFrame(columns=['geometry'], data=myPolygons.geoms)\n",
    "f,ax=plt.subplots()\n",
    "gdfR.boundary.plot(ax=ax, color='red')\n",
    "polygon.boundary.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"]\n",
    "minx, miny, maxx, maxy = polygon.bounds.iloc[0]\n",
    "minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon.bounds.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon.bounds.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"].bounds.to_dict()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in d.items():\n",
    "    # keyz=v.keys()\n",
    "    print(list(v.values())[0])\n",
    "    # print((list(keyz))[0])\n",
    "    # print(v[(list(keyz))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx=list(d['minx'].values())[0]\n",
    "miny=list(d['miny'].values())[0]\n",
    "maxx=list(d['maxx'].values())[0]\n",
    "maxy=list(d['maxy'].values())[0]\n",
    "minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, MultiPolygon, Polygon\n",
    "\n",
    "dx = (maxx - minx) / num_splitters  # width of a small part\n",
    "dy = (maxy - miny) / num_splitters  # height of a small part\n",
    "horizontal_splitters = [\n",
    "    LineString([(minx, miny + i * dy), (maxx, miny + i * dy)])\n",
    "    for i in range(num_splitters)\n",
    "]\n",
    "vertical_splitters = [\n",
    "    LineString([(minx + i * dx, miny), (minx + i * dx, maxy)])\n",
    "    for i in range(num_splitters)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitters = horizontal_splitters + vertical_splitters\n",
    "splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area(json.loads(coastsegmap.rois.gdf.to_json())['features'][1]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"][\"geometry\"].iloc[0].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"][\"geometry\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"][\"geometry\"].iloc[0]\n",
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import split\n",
    "result = polygon\n",
    "for splitter in splitters:\n",
    "    result = MultiPolygon(split(result, splitter))\n",
    "parts = [list(part.exterior.coords) for part in result.geoms]\n",
    "\n",
    "print(\"Number of individual tiles: {}\".format(len(parts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "from area import area\n",
    "import math\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_splitters(gdf:gpd.GeoDataFrame)->int:\n",
    "    # convert to geojson dictionary\n",
    "    roi_json = json.loads(gdf.to_json())\n",
    "    # only one feature is present select 1st feature's geometry\n",
    "    roi_geometry = roi_json['features'][0]['geometry']\n",
    "    # get area of entire shape as squared kilometers \n",
    "    area_km2=area(roi_geometry)/ 1e6\n",
    "    print(f\"Area(km^2): {area_km2}\")\n",
    "    # get minimum number of horizontal and vertical splitters to split area equally\n",
    "    num_splitters = math.ceil(math.sqrt(area_km2))\n",
    "    return num_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPolygon(polygon:gpd.GeoDataFrame, num_splitters:int):\n",
    "    minx, miny, maxx, maxy = polygon.bounds.iloc[0]\n",
    "    dx = (maxx - minx) / num_splitters  # width of a small part\n",
    "    dy = (maxy - miny) / num_splitters  # height of a small part\n",
    "    horizontal_splitters = [LineString([(minx, miny + i*dy), (maxx, miny + i*dy)]) for i in range(num_splitters)]\n",
    "    vertical_splitters = [LineString([(minx + i*dx, miny), (minx + i*dx, maxy)]) for i in range(num_splitters)]\n",
    "    splitters = horizontal_splitters + vertical_splitters\n",
    "    result = polygon[\"geometry\"].iloc[0]\n",
    "    for splitter in splitters:\n",
    "        result = MultiPolygon(split(result, splitter))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-121.94776 36.51249, -121.94776 36.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry\n",
       "0  POLYGON ((-121.94776 36.51249, -121.94776 36.4..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\src\\seg2map\\NAIP\\hidden_beach.geojson'\n",
    "with open(filename, \"r\") as f:\n",
    "        gpd_data = gpd.read_file(f)\n",
    "gpd_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area(km^2): 2.03344809745957\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-121.9484305701653 36.4951027815643 0.013545647427264385 0.018060058680759994\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,73.00826562180936)\"><g><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"0.00036120117361519987\" opacity=\"0.6\" d=\"M -121.94776167910305,36.495771672626546 L -121.94776167910305,36.50413281090468 L -121.94165774645167,36.50413281090468 L -121.94165774645167,36.495771672626546 L -121.94776167910305,36.495771672626546 z\" /><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"0.00036120117361519987\" opacity=\"0.6\" d=\"M -121.94165774645167,36.50413281090468 L -121.93555381380028,36.50413281090468 L -121.93555381380028,36.495771672626546 L -121.94165774645167,36.495771672626546 L -121.94165774645167,36.50413281090468 z\" /><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"0.00036120117361519987\" opacity=\"0.6\" d=\"M -121.94776167910305,36.50413281090468 L -121.94776167910305,36.51249394918281 L -121.94165774645167,36.51249394918281 L -121.94165774645167,36.50413281090468 L -121.94776167910305,36.50413281090468 z\" /><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"0.00036120117361519987\" opacity=\"0.6\" d=\"M -121.94165774645167,36.51249394918281 L -121.93555381380028,36.51249394918281 L -121.93555381380028,36.50413281090468 L -121.94165774645167,36.50413281090468 L -121.94165774645167,36.51249394918281 z\" /></g></g></svg>"
      ],
      "text/plain": [
       "<MULTIPOLYGON (((-121.948 36.496, -121.948 36.504, -121.942 36.504, -121.942...>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splitters = get_num_splitters(gpd_data)\n",
    "print(num_splitters)\n",
    "split_polygon = splitPolygon(gpd_data,num_splitters)\n",
    "split_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpd.GeoDataFrame(geometry=split_polygon)\n",
    "gpd.GeoSeries(split_polygon).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an roi out of geodataframe \n",
    "roi_gdf=coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"2\"]\n",
    "#number of horizontal & vertical splitters needed to split ROI into equally sized tiles whose area <=10km^2\n",
    "num_splitters = get_num_splitters(roi_gdf)\n",
    "num_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_polygon = splitPolygon(roi_gdf,num_splitters)\n",
    "split_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def create_time_series_dirs(sitename:str,years:List[int],num_features:int):\n",
    "    for featurenumber in range(num_features):\n",
    "        for year in years:\n",
    "            dir_path = os.path.abspath(sitename + os.sep + \"feature\" + str(featurenumber))\n",
    "            if not os.path.exists(dir_path):\n",
    "                os.makedirs(dir_path)\n",
    "            sub_dir=os.path.join(dir_path,str(year))\n",
    "            if not os.path.exists(sub_dir):\n",
    "                os.makedirs(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\1_USGS\\\\5_Doodleverse\\\\1_Seg2Map_fork\\\\seg2map\\\\doge_palace\\\\feature0\\\\2006'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitename=\"doge_palace\"\n",
    "years = [\"2006\", \"2009\",]\n",
    "num_features=1\n",
    "create_time_series_dirs(sitename,years,num_features)\n",
    "site_path=os.path.abspath(sitename + os.sep + \"feature\" + str(0)+ os.sep+years[0])\n",
    "site_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "def download_tiles(tiles:MultiPolygon,site_path:str,gee_collection:str,dates:Tuple[str]):\n",
    "    tile_coords= [list(part.exterior.coords) for part in tiles.geoms]\n",
    "    print(\"Number of individual tiles: {}\".format(len(tile_coords)))\n",
    "    for counter,tile in enumerate(tile_coords):\n",
    "        download_tile(tile,site_path,counter,gee_collection,dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tile(tile:List[Tuple],\n",
    "                  site_path:str,\n",
    "                  counter:int,\n",
    "                  gee_collection:str,\n",
    "                  dates:Tuple[str]):\n",
    "    # full path where downloaded image will be saved\n",
    "    OUT_RES_M = 0.5  # output raster spatial footprint in metres\n",
    "    \n",
    "    tile_path=os.path.join(site_path,\"chunk\"+ str(counter))\n",
    "    if os.path.exists(tile_path):\n",
    "        os.makedirs(tile_path)\n",
    "        \n",
    "    collection = ee.ImageCollection(gee_collection)\n",
    "    # print(f\"Collection : {collection}\")\n",
    "    polys = ee.Geometry.Polygon(tile)\n",
    "    # get center of polygon as longitude and latitude\n",
    "    centroid = polys.centroid()\n",
    "    lng, lat = centroid.getInfo()[\"coordinates\"]\n",
    "    # get portion of collection within tile\n",
    "    collection = collection.filterBounds(polys)\n",
    "    # only get images within the start and end date range\n",
    "    collection = collection.filterDate(dates[0], dates[1]).sort(\n",
    "                \"system:time_start\", True\n",
    "            )\n",
    "    count = collection.size().getInfo()\n",
    "    print(f\"Collection Size: {count}\")\n",
    "    if count == 0:\n",
    "        return\n",
    "    img_lst = collection.toList(1000)\n",
    "    img_names = []\n",
    "    for i in range(0, count):\n",
    "        image = ee.Image(img_lst.get(i))\n",
    "        name = image.get(\"system:index\").getInfo()\n",
    "        img_names.append(name)\n",
    "    \n",
    "    print(f\"img_names: {img_names}\")\n",
    "    # download each of the images from the collection    \n",
    "    for name in img_names:\n",
    "        image = ee.Image(gee_collection+\"/\" + name)\n",
    "        # full path where tif file will be saved\n",
    "        tile_path=os.path.join(site_path,\"chunk\"+ str(counter))\n",
    "        if not os.path.exists(tile_path):\n",
    "            os.makedirs(tile_path)\n",
    "        tif_path = os.path.join(tile_path,\"chunk\"+ str(counter)+ \"_\"+ name+ \".tif\")\n",
    "        multiband_path= os.path.join(tile_path,\"chunk\"+ str(counter)+ \"_\"+ name+ \"_multiband.tif\")\n",
    "        print(f\"tile_path: {tile_path}\")\n",
    "        print(f\"tif_path: {tif_path}\")\n",
    "        print(f\"multiband_path: {multiband_path}\")\n",
    "        # Export each band as one image\n",
    "        ee_export_image(\n",
    "            image,\n",
    "            tif_path,\n",
    "            scale=OUT_RES_M,\n",
    "            region=polys,\n",
    "            file_per_band=True,\n",
    "            crs=\"EPSG:4326\",)\n",
    "        # export single image with all bands\n",
    "        ee_export_image(\n",
    "            image,\n",
    "            multiband_path,\n",
    "            scale=OUT_RES_M,\n",
    "            region=polys,\n",
    "            file_per_band=False,\n",
    "            crs=\"EPSG:4326\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_export_image(\n",
    "    ee_object,\n",
    "    filename,\n",
    "    scale=None,\n",
    "    crs=None,\n",
    "    crs_transform=None,\n",
    "    region=None,\n",
    "    dimensions=None,\n",
    "    file_per_band=False,\n",
    "    format=\"ZIPPED_GEO_TIFF\",\n",
    "    unmask_value=None,\n",
    "    timeout=300,\n",
    "    proxies=None,\n",
    "):\n",
    "    \"\"\"Exports an ee.Image as a GeoTIFF.\n",
    "    Args:\n",
    "        ee_object (object): The ee.Image to download.\n",
    "        filename (str): Output filename for the exported image.\n",
    "        scale (float, optional): A default scale to use for any bands that do not specify one; ignored if crs and crs_transform is specified. Defaults to None.\n",
    "        crs (str, optional): A default CRS string to use for any bands that do not explicitly specify one. Defaults to None.\n",
    "        crs_transform (list, optional): a default affine transform to use for any bands that do not specify one, of the same format as the crs_transform of bands. Defaults to None.\n",
    "        region (object, optional): A polygon specifying a region to download; ignored if crs and crs_transform is specified. Defaults to None.\n",
    "        dimensions (list, optional): An optional array of two integers defining the width and height to which the band is cropped. Defaults to None.\n",
    "        file_per_band (bool, optional): Whether to produce a different GeoTIFF per band. Defaults to False.\n",
    "        format (str, optional):  One of: \"ZIPPED_GEO_TIFF\" (GeoTIFF file(s) wrapped in a zip file, default), \"GEO_TIFF\" (GeoTIFF file), \"NPY\" (NumPy binary format). If \"GEO_TIFF\" or \"NPY\",\n",
    "            filePerBand and all band-level transformations will be ignored. Loading a NumPy output results in a structured array.\n",
    "        unmask_value (float, optional): The value to use for pixels that are masked in the input image.\n",
    "            If the exported image contains zero values, you should set the unmask value to a  non-zero value so that the zero values are not treated as missing data. Defaults to None.\n",
    "        timeout (int, optional): The timeout in seconds for the request. Defaults to 300.\n",
    "        proxies (dict, optional): A dictionary of proxy servers to use. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(ee_object, ee.Image):\n",
    "        print(\"The ee_object must be an ee.Image.\")\n",
    "        return\n",
    "\n",
    "    if unmask_value is not None:\n",
    "        ee_object = ee_object.selfMask().unmask(unmask_value)\n",
    "        if isinstance(region, ee.Geometry):\n",
    "            ee_object = ee_object.clip(region)\n",
    "        elif isinstance(region, ee.FeatureCollection):\n",
    "            ee_object = ee_object.clipToCollection(region)\n",
    "\n",
    "    filename = os.path.abspath(filename)\n",
    "    basename = os.path.basename(filename)\n",
    "    name = os.path.splitext(basename)[0]\n",
    "    filetype = os.path.splitext(basename)[1][1:].lower()\n",
    "    filename_zip = filename.replace(\".tif\", \".zip\")\n",
    "\n",
    "    if filetype != \"tif\":\n",
    "        print(\"The filename must end with .tif\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(\"Generating URL ...\")\n",
    "        params = {\"name\": name, \"filePerBand\": file_per_band}\n",
    "\n",
    "        params[\"scale\"] = scale\n",
    "        if region is None:\n",
    "            region = ee_object.geometry()\n",
    "        if dimensions is not None:\n",
    "            params[\"dimensions\"] = dimensions\n",
    "        if region is not None:\n",
    "            params[\"region\"] = region\n",
    "        if crs is not None:\n",
    "            params[\"crs\"] = crs\n",
    "        if crs_transform is not None:\n",
    "            params[\"crs_transform\"] = crs_transform\n",
    "        params[\"format\"] = format\n",
    "\n",
    "        try:\n",
    "            url = ee_object.getDownloadURL(params)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred while downloading.\")\n",
    "            print(e)\n",
    "            return\n",
    "        print(f\"Downloading data from {url}\\nPlease wait ...\")\n",
    "        r = requests.get(url, stream=True, timeout=timeout, proxies=proxies)\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            print(\"An error occurred while downloading.\")\n",
    "            return\n",
    "\n",
    "        with open(filename_zip, \"wb\") as fd:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                fd.write(chunk)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"An error occurred while downloading.\")\n",
    "        print(r.json()[\"error\"][\"message\"])\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename_zip) as z:\n",
    "            z.extractall(os.path.dirname(filename))\n",
    "        os.remove(filename_zip)\n",
    "\n",
    "        if file_per_band:\n",
    "            print(f\"Data downloaded to {os.path.dirname(filename)}\")\n",
    "        else:\n",
    "            print(f\"Data downloaded to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=r'https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/5e076fc4649f0b802aa30a3d5d65e1e8-1b2b9fa9c5d8e91da880f0809490c0e7:getPixels'\n",
    "r = requests.get(url, stream=True)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\1_USGS\\\\5_Doodleverse\\\\1_Seg2Map_fork\\\\seg2map\\\\doge_palace\\\\feature0\\\\2006\\\\chunk0\\\\chunk0_m_3612125_se_10_1_20090622.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9404/3201784525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename_zip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_se_10_1_20090622.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_zip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\1_USGS\\\\5_Doodleverse\\\\1_Seg2Map_fork\\\\seg2map\\\\doge_palace\\\\feature0\\\\2006\\\\chunk0\\\\chunk0_m_3612125_se_10_1_20090622.zip'"
     ]
    }
   ],
   "source": [
    "filename_zip=r'C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_se_10_1_20090622.zip'\n",
    "os.mkdir()\n",
    "if not os.path.exists(filename_zip):\n",
    "    \n",
    "with open(filename_zip, \"wb\") as fd:\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "        fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with open(\"filename_zip.zip\", \"wb\") as fd:\n",
    "    zip_file = zipfile.ZipFile(fd, \"w\")\n",
    "    zip_file.writestr(\"string_file.txt\", \"UBG\")\n",
    "    zip_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9404/2423125933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filename_zip.zip\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UBG\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "with open(\"filename_zip.zip\", \"wb\") as fd:\n",
    "        fd.write(\"UBG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individual tiles: 4\n",
      "Collection Size: 4\n",
      "img_names: ['m_3612125_se_10_1_20090622', 'm_3612125_sw_10_1_20090622', 'm_3612133_ne_10_1_20090622', 'm_3612133_nw_10_1_20090622']\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_se_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_se_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/5e076fc4649f0b802aa30a3d5d65e1e8-ea3c1247fbaa19cc75f17881734037dd:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/bee4823341ba4a57885a68ddfe6ee165-4c1e74f6c1c36a02e5be0898a5a38e4d:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_se_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_sw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/f133eac805f7a81a46056ce1d6968094-0c5c08adc78151a3933b762ab61548cd:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/b3c7fa56f88d20dc875020d714e3b9e8-5d1d8e614c46e97a75e5a091702332b4:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_ne_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_ne_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/68fc33629f9e1902cb8c6ba454fe08c6-af78d3f63cb559d657375495a17b7665:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/c0c509c46291cdf79e6b6cd045508702-c88778b8b28b230740bfa18ddd60b35a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_ne_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_nw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_nw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/b88e02382d498138cbe64bb303f0bf8a-df6b706c3feca3869dee32d824a03bb4:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a10691c17131808a153b425cc4ea6f21-0d6a279e9950ff6530d15b56f16c877a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk0\\chunk0_m_3612133_nw_10_1_20090622_multiband.tif\n",
      "Collection Size: 4\n",
      "img_names: ['m_3612125_se_10_1_20090622', 'm_3612125_sw_10_1_20090622', 'm_3612133_ne_10_1_20090622', 'm_3612133_nw_10_1_20090622']\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_se_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_se_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/ebee7c3cd283fd428af0e18c41b8424d-5143d3ce79e40127f299b7615eb37d56:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/48e03cf84fabd9be390d543bffe2b184-86d9b94149d90e5d787efda6cba52272:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_se_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_sw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/4c56d4b7af8e0c1a3d94796b69d3eb1b-d1cc3d7e8928aaa9ec9e9c4375375f31:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/707cc2f1dd35b8de43b80c7d5245efb9-615c94a3995b5eccf3b7b43928415eca:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_ne_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_ne_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/29d3e0a1e93cdbb8e0f2bd66179d90b0-ac54a42049851d9568e86463332452d2:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/6e5ad02a3a3a84efadababc2cb61a3c2-b8f3399a9785eebffd6ba015376266ce:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_ne_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_nw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_nw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/dbf19c17c6700c2743331a2a18617d87-2b903ace9b6bc7502b1f3ddc486ce9aa:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/18df0e7986668a80007c8d5d58af0468-32058dfe888be52da4faa4ad3b40f6c7:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk1\\chunk1_m_3612133_nw_10_1_20090622_multiband.tif\n",
      "Collection Size: 2\n",
      "img_names: ['m_3612125_se_10_1_20090622', 'm_3612125_sw_10_1_20090622']\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_se_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_se_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/7b0441d3322a50e4b8e92a70a26df6e7-7dc9591e5ae6e9bcb4d33363c23da336:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/bbaaf6b87264576bd3b71fa3fbcc41a2-c805c58c07a61e3a6340492328a01ccb:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_se_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_sw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/c748abac8a25fd107137223321cfc628-9e1f77222a37c8ffc422694fe43e9750:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/e4e570035b37f87a6e74db7163b42361-a0350aefebbb2dbb7eb17d3a5892ae8a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk2\\chunk2_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "Collection Size: 2\n",
      "img_names: ['m_3612125_se_10_1_20090622', 'm_3612125_sw_10_1_20090622']\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_se_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_se_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/4c3ed73c08251a28a2cb898996db78df-74a9e6e89f937eaea57010a3faab5fe8:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/0dd4150b67737d9c57b46d3ad2b7de38-3f09385039a823015d408b2e5925db79:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_se_10_1_20090622_multiband.tif\n",
      "tile_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\n",
      "tif_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_sw_10_1_20090622.tif\n",
      "multiband_path: C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_sw_10_1_20090622_multiband.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a0039875f457fde2d88df06c0401089f-d0408cd73c0c8daad0c032813c2f5df5:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/8c7b91eb7f4603d36417006680488a2a-54aa26d9ccf9dc9e2f453732de2e565a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\1_USGS\\5_Doodleverse\\1_Seg2Map_fork\\seg2map\\doge_palace\\feature0\\2006\\chunk3\\chunk3_m_3612125_sw_10_1_20090622_multiband.tif\n"
     ]
    }
   ],
   "source": [
    "year=years[1]\n",
    "start_date = year + \"-01-01\"\n",
    "end_date = year + \"-12-31\"\n",
    "dates=(start_date,end_date)\n",
    "gee_collection = \"USDA/NAIP/DOQQ\"\n",
    "download_tiles(split_polygon,site_path,gee_collection,dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates=list(coastsegmap.rois.gdf[coastsegmap.rois.gdf[\"id\"]==\"1\"][\"geometry\"][0].exterior.coords)\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates=[list(x)for x in coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from area import area\n",
    "area_km2=area(rect['features'][0]['geometry'])/ 1e6\n",
    "area_km2\n",
    "# 0.00887890515200013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# get minimum number of horizontal and vertical splitters\n",
    "num_splitters = math.ceil(math.sqrt(area_km2/10))\n",
    "num_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minx, miny, maxx, maxy = polygon.bounds\n",
    "minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[1,2,3,4]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.remove(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=set([1,2,3,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.remove(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coastsegmap.map.find_layer('ROI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback(marker, html):\n",
    "    def callback(*args, **kwargs):\n",
    "        html.value = '''\n",
    "            <b>Glider Mission:</b><br>\n",
    "            {}\n",
    "        '''.format(marker.name)\n",
    "\n",
    "    return callback\n",
    "\n",
    "marker.on_mouseover(get_callback(marker, html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_callback(layer,coastseg_map):\n",
    "    def callback(*args, **kwargs):\n",
    "        print(\"yesss\")\n",
    "        coastseg_map.accordion.children[0].value=\"\"\" \n",
    "        <p>Layer: {}</p>\n",
    "        \"\"\".format(\n",
    "            layer\n",
    "        )\n",
    "        layer.style=delete_style\n",
    "\n",
    "    return callback\n",
    "\n",
    " # 'on_mouseout',\n",
    " # 'on_mouseover',\n",
    "# marker.on_mouseover(get_callback(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_callback(layer,coastseg_map):\n",
    "    def callback(*args, **kwargs):\n",
    "        print(\"yesss\")\n",
    "        coastseg_map.accordion.children[0].value=\"\"\" \n",
    "        <p>Layer: {}</p>\n",
    "        \"\"\".format(\n",
    "            layer\n",
    "        )\n",
    "        layer.style=normal_style\n",
    "\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(coastsegmap.map.find_layer('ROI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = coastsegmap.map.find_layer('ROI')\n",
    "# layer.on_hover(delete_callback(layer,coastsegmap))\n",
    "layer.on_mouseover(delete_callback(layer,coastsegmap))\n",
    "# layer.on_mouseout(normal_callback(layer,coastsegmap))\n",
    "existing_layer = coastsegmap.map.find_layer('ROI')\n",
    "if existing_layer is not None:\n",
    "    coastsegmap.map.remove_layer(existing_layer)\n",
    "coastsegmap.map.add_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_layer = coastsegmap.map.find_layer('ROI')\n",
    "if existing_layer is not None:\n",
    "    coastsegmap.map.remove_layer(existing_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.on_hover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_style = {'color': '#f73c02', 'fill_color': '#f73c02', 'fillOpacity': 0.1, 'weight': 1}\n",
    "unselect_style = {'color': '#555555', 'fill_color': '#555555', 'fillOpacity': 0.1, 'weight': 1}\n",
    "selected_style = {'color': '#ed2805', 'fill_color': '#ed2805', 'fillOpacity': 0.1, 'weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastsegmap.map.find_layer('ROI').style=unselect_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change layer to selected for deletion\n",
    "layer = coastsegmap.map.find_layer('ROI')\n",
    "layer.style=style={'color': '#ed2805', 'fill_color': '#ed2805', 'fillOpacity': 0.1, 'weight': 1}\n",
    "coastsegmap.map.add_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deselect layer for deletion\n",
    "layer = coastsegmap.map.find_layer('ROI')\n",
    "layer.style=style={'color': '#555555', 'fill_color': '#555555', 'fillOpacity': 0.1, 'weight': 1}\n",
    "coastsegmap.map.add_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coastsegmap.rois)\n",
    "print(coastsegmap.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = \"1\" if coastsegmap.ids == [] else  str(int(max(coastsegmap.ids))+1)\n",
    "new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coastsegmap.rois.gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\1_USGS\\CoastSeg\\repos\\2_CoastSeg\\CoastSeg_fork\\Seg2Map\\rois.geojson\"\n",
    "with open(filename, \"r\") as f:\n",
    "    gpd_data = gpd.read_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = gpd_data[gpd_data[\"id\"]!=id]\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=\"13\"\n",
    "new_gdf = gpd_data[gpd_data[\"id\"]==id]\n",
    "new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_gdf = gpd.GeoDataFrame(\n",
    "        pd.concat([main, new_gdf], ignore_index=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self):\n",
    "        self.gdf=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature =  Feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(feature,\"gdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpd_data) == gpd.GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "44f62ae1464d1bd94d46095295cce32bb1c15ab9a6effc0c50f8e5f2c4f28382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
