{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f327b92-3814-44ff-92b6-bd8488e6528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Local Imports\n",
    "from src.seg2map import map_interface\n",
    "from src.seg2map import log_maker #must be the first module loaded to create logs folder\n",
    "\n",
    "# External Imports\n",
    "import ee\n",
    "from google.auth import exceptions as google_auth_exceptions\n",
    "\n",
    "# suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a32ffb-a5ac-46c6-b728-4aa6fce87acf",
   "metadata": {},
   "source": [
    "## Authenticate and Initialize with Google Earth Engine (GEE)\n",
    "\n",
    "- Run this cell to initialize with GEE which will allow you to download remote sensing data from GEE.\n",
    "\n",
    "### First Time Users\n",
    "\n",
    "- In order to use Google Earth Engine (GEE) you will need to sign up to request access to use Google Earth Engine.https://signup.earthengine.google.com. You will only need to do this once and it takes only a day to get your account verified.\n",
    "\n",
    "### How `ee.Authenticate()` works\n",
    "\n",
    "- In order to initialize with GEE you will need an authorization token with is obtained by running `ee.Authenticate()`.This token lasts 7 days and during those 7 days you will not need to authenticate with google earth engine with an access code. Once the 7 days are up you will need to reauthenticate to use GEE again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa9963-0fc1-43f2-bbfa-3b8665481712",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except google_auth_exceptions.RefreshError as exception:\n",
    "    print(\"Please authenticate with Google:\\n\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da2172-9ac3-49ce-8d01-052f34ea711d",
   "metadata": {},
   "source": [
    "# How to Use The Map\n",
    "\n",
    "---\n",
    "1.  Click `Save Settings` Button\n",
    "2. Use the rectangle tool to draw a ROI along the coastline.\n",
    "3. Load transects into your bounding box with the `Load Transects` button. If any exist for the bounding box you selected they should appear.\n",
    "4. Click the ROIs you want to download.\n",
    "5. Once you've selected all the ROIs you want to download click `Downlod Imagery`\n",
    " - If any of the ROIs succesfully download they will have their own folder with all their data in the `data` directory in the `seg2map` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1cc88-c52a-4006-87dd-091774569cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from coastseg.map_UI import UI\n",
    "from src.seg2map.map_UI import UI\n",
    "from src.seg2map.map_interface import Seg2Map\n",
    "\n",
    "seg2map=Seg2Map()\n",
    "seg2map_ui = UI(seg2map)\n",
    "seg2map_ui.create_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730cebd-9bac-4e11-b640-1b2f30aa7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(lambda x:x.name, seg2map.map.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b8ff2-c5c6-4b60-9063-bdbf5e98cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_layers = [layer for layer in seg2map.original_layers + seg2map.seg_layers if layer in seg2map.map.layers]\n",
    "print(list(map(lambda x:x.name,remove_layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8040c64-867c-4a23-9e1b-d5cca6010057",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_layers = [layer for layer in seg2map.original_layers + seg2map.seg_layers if layer in seg2map.map.layers]\n",
    "print(list(map(lambda x:x.name,remove_layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda45534-a112-4e72-a516-ad3538750dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [layer for layer in seg2map.original_layers + seg2map.seg_layers]\n",
    "print(list(map(lambda x:x.name,layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ea1b4-081c-41c7-8f2b-fab74c24be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seg2map import log_maker\n",
    "from src.seg2map.models_UI import UI_Models\n",
    "models_ui = UI_Models()\n",
    "models_ui.create_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aed1eb-0450-4027-8e1d-44cbd51465e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba1b70-0979-4e2b-943a-c2207e43b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8b65a-9b99-4eda-b4ed-7573b93b4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal\n",
    "from typing import List\n",
    "\n",
    "def build_vrt(vrt: str, files: List[str], resample_name: str) -> None:\n",
    "    \"\"\"builds .vrt file which will hold information needed for overlay\n",
    "    Args:\n",
    "        vrt (:obj:`string`): name of vrt file, which will be created\n",
    "        files (:obj:`list`): list of file names for merging\n",
    "        resample_name (:obj:`string`): name of resampling method\n",
    "    \"\"\"\n",
    "\n",
    "    options = gdal.BuildVRTOptions(srcNodata=0)\n",
    "    virtual_dataset=gdal.BuildVRT(destName=vrt, srcDSOrSrcDSTab=files, options=options)\n",
    "    virtual_dataset.FlushCache()\n",
    "    virtual_dataset = None\n",
    "    print(os.path.exists(vrt))\n",
    "    add_pixel_fn(vrt, resample_name)\n",
    "\n",
    "\n",
    "\n",
    "def add_pixel_fn(filename: str, resample_name: str) -> None:\n",
    "    \"\"\"inserts pixel-function into vrt file named 'filename'\n",
    "    Args:\n",
    "        filename (:obj:`string`): name of file, into which the function will be inserted\n",
    "        resample_name (:obj:`string`): name of resampling method\n",
    "    \"\"\"\n",
    "\n",
    "    header = \"\"\"  <VRTRasterBand dataType=\"Byte\" band=\"1\" subClass=\"VRTDerivedRasterBand\">\"\"\"\n",
    "    contents = \"\"\"\n",
    "    <PixelFunctionType>{0}</PixelFunctionType>\n",
    "    <PixelFunctionLanguage>Python</PixelFunctionLanguage>\n",
    "    <PixelFunctionCode><![CDATA[{1}]]>\n",
    "    </PixelFunctionCode>\"\"\"\n",
    "\n",
    "    lines = open(filename, 'r').readlines()\n",
    "    lines[3] = header  # FIX ME: 3 is a hand constant\n",
    "    lines.insert(4, contents.format(resample_name,\n",
    "                                    get_resample(resample_name)))\n",
    "    open(filename, 'w').write(\"\".join(lines))\n",
    "\n",
    "\n",
    "def get_resample(name: str) -> str:\n",
    "    \"\"\"retrieves code for resampling method\n",
    "    Args:\n",
    "        name (:obj:`string`): name of resampling method\n",
    "    Returns:\n",
    "        method :obj:`string`: code of resample method\n",
    "    \"\"\"\n",
    "\n",
    "    methods = {\n",
    "        \"first\":\n",
    "        \"\"\"\n",
    "import numpy as np\n",
    "def first(in_ar, out_ar, xoff, yoff, xsize, ysize, raster_xsize,raster_ysize, buf_radius, gt, **kwargs):\n",
    "    y = np.ones(in_ar[0].shape)\n",
    "    for i in reversed(range(len(in_ar))):\n",
    "        mask = in_ar[i] == 0\n",
    "        y *= mask\n",
    "        y += in_ar[i]\n",
    "    np.clip(y,0,255, out=out_ar)\n",
    "\"\"\",\n",
    "        \"last\":\n",
    "        \"\"\"\n",
    "import numpy as np\n",
    "def last(in_ar, out_ar, xoff, yoff, xsize, ysize, raster_xsize,raster_ysize, buf_radius, gt, **kwargs):\n",
    "    y = np.ones(in_ar[0].shape)\n",
    "    for i in range(len(in_ar)):\n",
    "        mask = in_ar[i] == 0\n",
    "        y *= mask\n",
    "        y += in_ar[i]\n",
    "    np.clip(y,0,255, out=out_ar)\n",
    "\"\"\",\n",
    "        \"max\":\n",
    "        \"\"\"\n",
    "import numpy as np\n",
    "def max(in_ar, out_ar, xoff, yoff, xsize, ysize, raster_xsize,raster_ysize, buf_radius, gt, **kwargs):\n",
    "    y = np.max(in_ar, axis=0)\n",
    "    np.clip(y,0,255, out=out_ar)\n",
    "\"\"\",\n",
    "        \"average\":\n",
    "        \"\"\"\n",
    "import numpy as np\n",
    "def average(in_ar, out_ar, xoff, yoff, xsize, ysize, raster_xsize,raster_ysize, buf_radius, gt, **kwargs):\n",
    "    div = np.zeros(in_ar[0].shape)\n",
    "    for i in range(len(in_ar)):\n",
    "        div += (in_ar[i] != 0)\n",
    "    div[div == 0] = 1\n",
    "    \n",
    "    y = np.sum(in_ar, axis = 0, dtype = 'uint16')\n",
    "    y = y / div\n",
    "    \n",
    "    np.clip(y,0,255, out = out_ar)\n",
    "\"\"\"}\n",
    "\n",
    "    if name not in methods:\n",
    "        raise ValueError(\n",
    "            \"ERROR: Unrecognized resampling method (see documentation): '{}'.\".\n",
    "            format(name))\n",
    "\n",
    "    return methods[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59be26a-d58c-430d-a006-2ff34357b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(src_files: str, dest_path: str, create_jpg: bool = True) -> str:\n",
    "    \"\"\"Merge a list of GeoTIFF files into a single JPEG file.\n",
    "\n",
    "    Args:\n",
    "    src_files (List[str]): A list of file paths to be merged.\n",
    "    dest_path (str): The path to the output JPEG file.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the output JPEG file.\n",
    "    \"\"\"\n",
    "    # Check if path to source exists\n",
    "    for file in src_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"{file} not found.\")\n",
    "    try:\n",
    "        ## create vrt(virtual world format) file\n",
    "        # Create VRT file\n",
    "        vrt_options = gdal.BuildVRTOptions(\n",
    "            resampleAlg=\"nearest\", srcNodata=0, VRTNodata=0\n",
    "        )\n",
    "\n",
    "        virtual_dataset = gdal.BuildVRT(dest_path, src_files, options=vrt_options)\n",
    "        # flushing the cache causes the vrt file to be created\n",
    "        virtual_dataset.FlushCache()\n",
    "        # reset the dataset object\n",
    "        virtual_dataset = None\n",
    "        # print(f\"dest_path: {dest_path}\")\n",
    "        # parent_dir = os.path.dirname(dest_path)\n",
    "        # tmp_path = os.path.join(parent_dir,'tmp.vrt')\n",
    "        # print(f\"tmp_path: {tmp_path}\")\n",
    "        \n",
    "        # build_vrt(tmp_path, src_files, 'max')\n",
    "        \n",
    "        # gdal.SetConfigOption('GDAL_VRT_ENABLE_PYTHON', 'YES')\n",
    "\n",
    "        # print(f\"dest_path: {dest_path}\")\n",
    "        # kwargs = {\n",
    "        #     'format': 'GTiff',\n",
    "        #     'outputType': gdal.GDT_Byte\n",
    "        # }\n",
    "        # virtual_dataset = gdal.Translate(destName=dest_path, srcDS=tmp_path,kwargs)\n",
    "        # virtual_dataset.FlushCache()\n",
    "        # virtual_dataset = None\n",
    "        # print(os.path.exists(dest_path))\n",
    "\n",
    "\n",
    "        # print(f\"after new  build_vrt dest_path: {dest_path}\")\n",
    "\n",
    "        # create geotiff (.tiff) from merged vrt file\n",
    "        tif_path = dest_path.replace(\".vrt\", \".tif\")\n",
    "        print(f\"tif_path: {tif_path}\")\n",
    "        virtual_dataset = gdal.Translate(\n",
    "            tif_path,\n",
    "            creationOptions=[\"COMPRESS=LZW\", \"TILED=YES\"],\n",
    "            srcDS=dest_path,\n",
    "        )\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(f\"dest_path(tif_path): {tif_path}\")\n",
    "\n",
    "        if create_jpg:\n",
    "            # convert .vrt to .jpg file\n",
    "            virtual_dataset = gdal.Translate(\n",
    "                dest_path.replace(\".vrt\", \".jpg\"),\n",
    "                creationOptions=[\"WORLDFILE=YES\", \"QUALITY=100\"],\n",
    "                srcDS=dest_path.replace(\".vrt\", \".tif\"),\n",
    "            )\n",
    "            virtual_dataset.FlushCache()\n",
    "            virtual_dataset = None\n",
    "            print(f\"dest_path: {dest_path.replace('.vrt', '.jpg')}\")\n",
    "\n",
    "        return dest_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de508c5-c1cd-4ad5-8c93-3ced2c128860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(src_files: str, dest_path: str, create_jpg: bool = True) -> str:\n",
    "    \"\"\"Merge a list of GeoTIFF files into a single JPEG file.\n",
    "\n",
    "    Args:\n",
    "    src_files (List[str]): A list of file paths to be merged.\n",
    "    dest_path (str): The path to the output JPEG file.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the output JPEG file.\n",
    "    \"\"\"\n",
    "    # Check if path to source exists\n",
    "    for file in src_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"{file} not found.\")\n",
    "    try:\n",
    "        ## create vrt(virtual world format) file\n",
    "        # Create VRT file\n",
    "        vrt_options = gdal.BuildVRTOptions(\n",
    "            resampleAlg=\"nearest\", srcNodata=0, VRTNodata=0\n",
    "        )\n",
    "\n",
    "        virtual_dataset = gdal.BuildVRT(dest_path, src_files, options=vrt_options)\n",
    "        # flushing the cache causes the vrt file to be created\n",
    "        virtual_dataset.FlushCache()\n",
    "        # reset the dataset object\n",
    "        virtual_dataset = None\n",
    "        # create geotiff (.tiff) from merged vrt file\n",
    "        tif_path = dest_path.replace(\".vrt\", \".tif\")\n",
    "        print(f\"tif_path: {tif_path}\")\n",
    "        virtual_dataset = gdal.Translate(\n",
    "            tif_path,\n",
    "            creationOptions=[\"COMPRESS=LZW\", \"TILED=YES\"],\n",
    "            srcDS=dest_path,\n",
    "        )\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(f\"dest_path(tif_path): {tif_path}\")\n",
    "\n",
    "        if create_jpg:\n",
    "            # convert .vrt to .jpg file\n",
    "            virtual_dataset = gdal.Translate(\n",
    "                dest_path.replace(\".vrt\", \".jpg\"),\n",
    "                creationOptions=[\"WORLDFILE=YES\", \"QUALITY=100\"],\n",
    "                srcDS=dest_path.replace(\".vrt\", \".tif\"),\n",
    "            )\n",
    "            virtual_dataset.FlushCache()\n",
    "            virtual_dataset = None\n",
    "            print(f\"dest_path: {dest_path.replace('.vrt', '.jpg')}\")\n",
    "\n",
    "        return dest_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff8995b-f18a-47b9-bf80-8e3d0c595b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tif_path: C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit_2.tif\n",
      "dest_path(tif_path): C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit_2.tif\n",
      "dest_path: C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit_2.jpg\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "src_path=r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010'\n",
    "tif_files = glob(os.path.join(src_path, \"*.tif\"))\n",
    "tif_files = [file for file in tif_files if \"merged_multispectral\" not in file]\n",
    "\n",
    "dst_path = os.path.join(src_path, \"merged_multispectral_fruit_2.vrt\")\n",
    "merged_file = merge_files(tif_files, dst_path, create_jpg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf054709-8a64-405d-903d-bc874ec0bab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25458\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Example usage\n",
    "input_filename =r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit_2.jpg'\n",
    "\n",
    "# Load the input image\n",
    "with Image.open(input_filename) as image:\n",
    "    # Convert the image to a NumPy array\n",
    "    array3 = np.array(image)\n",
    "reshaped_array3 =array3.reshape(-1, array3.shape[2])\n",
    "unique_colors = np.unique(reshaped_array3,axis=0)\n",
    "print(len(unique_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150a8b4-a682-4436-a8ed-85692a35679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbf5f8-f267-46f8-bbe3-57b7ec4623a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db379b92-3e76-43cc-b8c8-2ef7f2ad9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(src_files: str, dest_path: str, create_jpg: bool = True) -> str:\n",
    "    \"\"\"Merge a list of GeoTIFF files into a single JPEG file.\n",
    "\n",
    "    Args:\n",
    "    src_files (List[str]): A list of file paths to be merged.\n",
    "    dest_path (str): The path to the output JPEG file.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the output JPEG file.\n",
    "    \"\"\"\n",
    "    # Check if path to source exists\n",
    "    for file in src_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"{file} not found.\")\n",
    "    try:\n",
    "        ## create vrt(virtual world format) file\n",
    "        # Create VRT file\n",
    "        vrt_options = gdal.BuildVRTOptions(\n",
    "            resampleAlg=\"mode\", srcNodata=0, VRTNodata=0\n",
    "        )\n",
    "        print(f\"dest_path: {dest_path}\")\n",
    "        parent_dir = os.path.dirname(dest_path)\n",
    "        tmp_path = os.path.join(parent_dir,'tmp.vrt')\n",
    "        print(f\"tmp_path: {tmp_path}\")\n",
    "        \n",
    "        build_vrt(tmp_path, src_files, 'max')\n",
    "        \n",
    "        gdal.SetConfigOption('GDAL_VRT_ENABLE_PYTHON', 'YES')\n",
    "\n",
    "        # parent_dir = os.path.dirname(dest_path)\n",
    "        # dst_path = os.path.join(parent_dir,'final.vrt')\n",
    "        print(f\"dest_path: {dest_path}\")\n",
    "        virtual_dataset = gdal.Translate(destName=dest_path, srcDS=tmp_path)\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(os.path.exists(dest_path))\n",
    "\n",
    "        # if os.path.isfile(constants.TEMP_VRT_FILE):\n",
    "        #     os.remove(constants.TEMP_VRT_FILE)\n",
    "        # creates a virtual world file using all the tifs and overwrites any pre-existing .vrt\n",
    "        # virtual_dataset = gdal.BuildVRT(dest_path, src_files, options=vrt_options)\n",
    "        # # flushing the cache causes the vrt file to be created\n",
    "        # virtual_dataset.FlushCache()\n",
    "        # # reset the dataset object\n",
    "        # virtual_dataset = None\n",
    "\n",
    "#         print(f\"dest_path: {dest_path}\")\n",
    "        # virtual_dataset = build_vrt(dest_path, src_files, 'max')\n",
    "        # virtual_dataset.FlushCache()\n",
    "        # virtual_dataset = None\n",
    "\n",
    "        print(f\"after new  build_vrt dest_path: {dest_path}\")\n",
    "\n",
    "        # create geotiff (.tiff) from merged vrt file\n",
    "        tif_path = dest_path.replace(\".vrt\", \".tif\")\n",
    "        print(f\"tif_path: {tif_path}\")\n",
    "        virtual_dataset = gdal.Translate(\n",
    "            tif_path,\n",
    "            creationOptions=[\"COMPRESS=LZW\", \"TILED=YES\"],\n",
    "            srcDS=dest_path,\n",
    "        )\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(f\"dest_path(tif_path): {tif_path}\")\n",
    "\n",
    "        if create_jpg:\n",
    "            # convert .vrt to .jpg file\n",
    "            virtual_dataset = gdal.Translate(\n",
    "                dest_path.replace(\".vrt\", \".jpg\"),\n",
    "                creationOptions=[\"WORLDFILE=YES\", \"QUALITY=100\"],\n",
    "                srcDS=dest_path.replace(\".vrt\", \".tif\"),\n",
    "            )\n",
    "            virtual_dataset.FlushCache()\n",
    "            virtual_dataset = None\n",
    "            print(f\"dest_path: {dest_path.replace('.vrt', '.jpg')}\")\n",
    "\n",
    "        return dest_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010b9c2-dd5e-488b-9c96-bcaf1b4d2aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb722e-8349-4d62-ae15-f4f1837dd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geotiff (.tiff) from merged vrt file\n",
    "# dest_path = r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit.vrt'\n",
    "# tif_path = dest_path.replace(\".vrt\", \".tif\")\n",
    "# virtual_dataset = gdal.Translate(\n",
    "#     tif_path,\n",
    "#     creationOptions=[\"COMPRESS=LZW\", \"TILED=YES\"],\n",
    "#     srcDS=dest_path,\n",
    "# )\n",
    "# virtual_dataset.FlushCache()\n",
    "# virtual_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6a679-8e8a-49ed-bf22-3f8e51c8ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def merge_files(src_files: str, dest_path: str, create_jpg: bool = True) -> str:\n",
    "    \"\"\"Merge a list of GeoTIFF files into a single JPEG file.\n",
    "\n",
    "    Args:\n",
    "    src_files (List[str]): A list of file paths to be merged.\n",
    "    dest_path (str): The path to the output JPEG file.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the output JPEG file.\n",
    "    \"\"\"\n",
    "    # Check if path to source exists\n",
    "    for file in src_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"{file} not found.\")\n",
    "    try:\n",
    "        ## create vrt(virtual world format) file\n",
    "        # Create VRT file\n",
    "        vrt_options = gdal.BuildVRTOptions(\n",
    "            resampleAlg=\"mode\", srcNodata=0, VRTNodata=0\n",
    "        )\n",
    "        print(f\"dest_path: {dest_path}\")\n",
    "        parent_dir = os.path.dirname(dest_path)\n",
    "        tmp_path = os.path.join(parent_dir,'tmp.vrt')\n",
    "        print(f\"tmp_path: {tmp_path}\")\n",
    "        \n",
    "        build_vrt(tmp_path, src_files, 'max')\n",
    "        \n",
    "        gdal.SetConfigOption('GDAL_VRT_ENABLE_PYTHON', 'YES')\n",
    "\n",
    "        print(f\"dest_path: {dest_path}\")\n",
    "        virtual_dataset = gdal.Translate(destName=dest_path, srcDS=tmp_path)\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(os.path.exists(dest_path))\n",
    "\n",
    "\n",
    "        print(f\"after new  build_vrt dest_path: {dest_path}\")\n",
    "\n",
    "        # create geotiff (.tiff) from merged vrt file\n",
    "        tif_path = dest_path.replace(\".vrt\", \".tif\")\n",
    "        print(f\"tif_path: {tif_path}\")\n",
    "        virtual_dataset = gdal.Translate(\n",
    "            tif_path,\n",
    "            creationOptions=[\"COMPRESS=LZW\", \"TILED=YES\"],\n",
    "            srcDS=dest_path,\n",
    "        )\n",
    "        virtual_dataset.FlushCache()\n",
    "        virtual_dataset = None\n",
    "        print(f\"dest_path(tif_path): {tif_path}\")\n",
    "\n",
    "        if create_jpg:\n",
    "            # convert .vrt to .jpg file\n",
    "            virtual_dataset = gdal.Translate(\n",
    "                dest_path.replace(\".vrt\", \".jpg\"),\n",
    "                creationOptions=[\"WORLDFILE=YES\", \"QUALITY=100\"],\n",
    "                srcDS=dest_path.replace(\".vrt\", \".tif\"),\n",
    "            )\n",
    "            virtual_dataset.FlushCache()\n",
    "            virtual_dataset = None\n",
    "            print(f\"dest_path: {dest_path.replace('.vrt', '.jpg')}\")\n",
    "\n",
    "        return dest_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "\n",
    "src_path=r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010'\n",
    "tif_files = glob(os.path.join(src_path, \"*.tif\"))\n",
    "tif_files = [file for file in tif_files if \"merged_multispectral\" not in file]\n",
    "\n",
    "dst_path = os.path.join(src_path, \"merged_multispectral_fruit_2.vrt\")\n",
    "merged_file = merge_files(tif_files, dst_path, create_jpg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14348905-ad6a-4c1f-aadf-193cb09f772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c430b2-854b-4020-811c-ff03da0ab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b48f0-1b3b-4695-86b2-c5f2cb2339e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a45878-4023-43b7-99e8-a885d0d5eacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db6b9b-e92a-49e1-bb41-e2b2148fff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seg2map import common\n",
    "from glob import glob\n",
    "import os\n",
    "session_year_path =  r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\new_official_test_site_aaai-buildings\\2010'\n",
    "png_files = glob(os.path.join(session_year_path, \"*.png\"))\n",
    "png_files = common.filter_files(png_files,[\".*overlay.*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5867a7-e6e3-4ae6-93d7-6d798a959d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be568da9-d3e3-43f0-b18f-44d1e12a36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def array_to_jpg(array, filename):\n",
    "    # Ensure that the array has 3 channels (i.e. is an RGB image)\n",
    "    if array.shape[2] != 3:\n",
    "        raise ValueError(\"Array must have 3 channels (i.e. be an RGB image)\")\n",
    "    \n",
    "    # Normalize the array values to the range [0, 255]\n",
    "    array = (array * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create a Pillow image from the array\n",
    "    image = Image.fromarray(array)\n",
    "    \n",
    "    # Save the image as a JPEG file\n",
    "    image.save(filename, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3a0e4-4def-45b4-a37e-41fb638731bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "array = np.random.rand(100, 100, 3)  # Generate a random RGB image\n",
    "filename = \"example.jpg\"  # Filename to save the JPEG image to\n",
    "array_to_jpg(array, filename)  # Convert the array to a JPEG image and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19532ef-c65b-4c3f-becb-5ccd522de69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def isolate_colors(input_filename, output_prefix):\n",
    "    # Open the input image and convert it to a NumPy array\n",
    "    with Image.open(input_filename) as image:\n",
    "        array = np.array(image)\n",
    "    \n",
    "    # Find the unique colors in the image\n",
    "    unique_colors = np.unique(array.reshape(-1, array.shape[2]), axis=0)\n",
    "    \n",
    "    # For each unique color, create a mask that isolates that color\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        # Create a mask that isolates pixels of this color\n",
    "        mask = np.all(array == color, axis=2)\n",
    "        \n",
    "        # Convert the mask to a PIL image and save it\n",
    "        mask_image = Image.fromarray(mask.astype(np.uint8) * 255)\n",
    "        mask_image.save(f\"{output_prefix}_{i}.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0d3e5-2588-4440-a89b-9b2aa1c1193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def isolate_colors(input_filename, output_prefix):\n",
    "    # Open the input image and convert it to a NumPy array\n",
    "    with Image.open(input_filename) as image:\n",
    "        array = np.array(image)\n",
    "    \n",
    "    # Find the unique colors in the image\n",
    "    unique_colors = np.unique(array.reshape(-1, array.shape[2]), axis=0)\n",
    "    \n",
    "    # Create a new array for the output image, initialized to transparent black\n",
    "    output_array = np.zeros_like(array, dtype=np.uint8)\n",
    "    output_array[..., 3] = 0\n",
    "    \n",
    "    # For each unique color, create a mask that isolates that color\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        # Create a mask that isolates pixels of this color\n",
    "        mask = np.all(array == color, axis=2)\n",
    "        \n",
    "        # Apply the mask to the output array, setting pixels of this color to opaque\n",
    "        output_array[mask, :] = color\n",
    "        output_array[mask, 3] = 255\n",
    "    \n",
    "    # Convert the output array to a PIL image and save it\n",
    "    output_image = Image.fromarray(output_array)\n",
    "    output_image.save(f\"{output_prefix}.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbd6ab-7ecf-4c39-b19c-ce3b08347d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def isolate_colors(input_filename, output_prefix):\n",
    "    # Open the input image and convert it to a NumPy array\n",
    "    with Image.open(input_filename) as image:\n",
    "        array = np.array(image)\n",
    "    \n",
    "    # Find the unique colors in the image\n",
    "    unique_colors = np.unique(array.reshape(-1, array.shape[2]), axis=0)\n",
    "    \n",
    "    # For each unique color, create a mask that isolates that color\n",
    "    for i, color in enumerate(unique_colors):\n",
    "        # Create a mask that isolates pixels of this color\n",
    "        mask = np.all(array == color, axis=2)\n",
    "        \n",
    "        # Create a new output image with pixels of this color set to the original color and other pixels set to black\n",
    "        output_array = np.zeros_like(array, dtype=np.uint8)\n",
    "        output_array[mask] = color\n",
    "        output_image = Image.fromarray(output_array)\n",
    "        \n",
    "        # Save the output image\n",
    "        output_image.save(f\"{output_prefix}_{i}.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efd33b-a371-4aeb-9d57-084c46c951d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_filename = r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\new_official_test_site\\2010\\multiband0_USDA_NAIP_DOQQ_m_4012415_ne_10_1_20100629.png'\n",
    "output_prefix = \"output_test_two\"  # Prefix to use for the output filenames\n",
    "isolate_colors(input_filename, output_prefix)  # Isolate each color in the input image and save the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c6185-08f5-4bf7-a765-9491bc651332",
   "metadata": {},
   "outputs": [],
   "source": [
    "'output_test_11.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809283e-924f-4856-a16f-b6f76f90fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Example usage\n",
    "input_filename =r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\test_2_\\2010\\multiband0_USDA_NAIP_DOQQ_m_4012415_ne_10_1_20100629.png'\n",
    "# input_filename = r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit.jpg'\n",
    "output_prefix = \"output_test_two\"  # Prefix to use for the output filenames\n",
    "# isolate_colors(input_filename, output_prefix)  # Isolate each color in the input image and save the masks\n",
    "\n",
    "# Load the input image\n",
    "with Image.open(input_filename) as image:\n",
    "    # Convert the image to a NumPy array\n",
    "    array3 = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062655e9-dddb-4e22-a8b7-3154a2ff2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Example usage\n",
    "input_filename =r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\test_2_\\2010\\multiband0_USDA_NAIP_DOQQ_m_4012415_ne_10_1_20100629.png'\n",
    "\n",
    "# Load the input image\n",
    "with Image.open(input_filename) as image:\n",
    "    # Convert the image to a NumPy array\n",
    "    array3 = np.array(image)\n",
    "reshaped_array3 =array3.reshape(-1, array3.shape[2])\n",
    "unqiue_colors = np.unique(reshaped_array3,axis=0)\n",
    "print(unqiue_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80009740-48b2-4d0d-a042-bca090976b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array3 =array3.reshape(-1, array3.shape[2])\n",
    "reshaped_array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e873dfa-c9c8-4fee-8465-dde8e8ee0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unqiue_colors = np.unique(reshaped_array3,axis=0)\n",
    "unqiue_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0117d-84d4-4135-a64d-97e900a84f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfcdd75-4c6e-4ed6-bb2e-853c27d389c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74cb4a-18f9-4f25-ba3a-7c44b6f074d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array3 =array3.reshape(-1, array3.shape[2])\n",
    "reshaped_array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0004d-8517-404d-8a7c-a65937c4238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array3.size/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe9604-ba8b-4246-a985-05837d820d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "unqiue_colors = np.unique(reshaped_array3,axis=0)\n",
    "unqiue_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f96c10-9954-48da-8072-b555edab7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unqiue_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da39e8-274b-4db6-92ed-287bc0868366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "input_filename = r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\new_official_test_site\\2010\\multiband1_USDA_NAIP_DOQQ_m_4012415_ne_10_1_20100629.png'\n",
    "# Load the input image\n",
    "with Image.open('multiband2_USDA_NAIP_DOQQ_m_4012415_ne_10_1_20100629.png') as image:\n",
    "    # Convert the image to a NumPy array\n",
    "    array2 = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8cbae-d2e4-4e53-8c46-ad8f4b3ad044",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array2 =array2.reshape(-1, array2.shape[2])\n",
    "reshaped_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1311f9c-fa57-4589-9f01-4c3f2bfcff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array2[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05351a16-b27a-42c8-b0b9-c2b649fac12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(reshaped_array2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435e7a7-a2ba-407f-b9b9-78cb3008abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "path = r'C:\\1_USGS\\4_seg2map\\seg2map\\sessions\\mode_experiment\\2010\\merged_multispectral_fruit.jpg'\n",
    "# Load the input image\n",
    "with Image.open(path) as image:\n",
    "    # Convert the image to a NumPy array\n",
    "    array = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea174f-f1a7-4241-8ead-ff57f792f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d30a36-3cf5-4b60-85b7-ad1334fccb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "array[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ec84d-6e2f-4ad6-8bc3-8b06ce220f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array =array.reshape(-1, array.shape[2])\n",
    "reshaped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c882b3-3547-4d83-9687-d6a42839fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f8ed7-6709-4006-a2c4-1e7c4cb0e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(reshaped_array[0:10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cb7d7-99b4-4439-9908-b65100c22724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(reshaped_array[0:5000],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f946f-9ab1-4e66-9ef0-c90172bf1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(reshaped_array[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d1536-0583-4ff4-839d-dcfc2d9c004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19260b5b-b1ee-4eb6-a286-caf704d1a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30473cde-70a7-4c1d-808e-5094e2c17312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981edfb-2c20-41b5-8385-22e2fbbf6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(array[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b3a8d-2f61-44de-b382-25ee9da81bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(array[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e30df0-6219-4045-9c25-e1362dcd4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb5e69-c568-4656-9d70-2d293b2f5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f24b1-da79-41a5-bf8d-dad6283ee923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
